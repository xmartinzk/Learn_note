# 线性回归

## 房价问题
* 数据集构成
  * 训练集
  * 样本数量m
  * 样本特征$x_i$
  * 目标变量y



## 假设函数
  * 假设函数
  $$h(x)=\theta_0+\theta_1 x$$
  * 模型参数$\theta_0,\theta_1$
## 代价函数
  * 损失函数、代价函数（loss/cost function）:平方误差代价函数
  
$$
J(\theta_0,\theta_1)=\frac{1}{2m}\sum_1^m(h(x_i)-y_i)^2 
$$
  * 目标函数：
$$
minimize_{\theta_0,\theta_1} J(\theta_0,\theta_1)
$$

## 梯度下降

* 目标

$$
min_{\theta_1,\theta_2,\dots}J(\theta_1,\theta_2,\dots)
$$
* 给定$\theta$的初始值。不断修改$\theta$的值，使代价函数最小。统计学上使用全局的最小二乘法实现参数估计，计算机科学上使用局部迭代的梯度下降算法实现参数估计。
* 梯度下降算法的公式

$$
\theta_j = \theta_j - \alpha\frac{\partial}{\partial \theta_j}J(\theta_1,\theta_2,\dots)
$$
* 吴恩达给出了梯度下降函数的解释，当导数为正时，表示函数递增，此时自变量减去一个正值，自变量减小，函数值下降。当导数为负时，表示函数递减，此时自变量减去一个负值，自变量增加，函数值增加。

## batch梯度下降

* 每一步都遍历了样本中所有的数据。

## 梯度下降算法与最小二乘法区别

* 给出假设函数（这是拟合的函数）
* 使用最小二乘算法进行参数估计。这个是统计学的方法，利用样本的统计学特征，一次性全局计算准确的最小损失函数。
* 使用梯度下降算法，进行参数估计。这是一个迭代的方法，利用每一条数据，更新参数。