。图上的学习任务包括：

1. 图节点分类任务：图中每个节点都有对应的特征，当我们已知一部分节点的类别时，可以对未知类型的节点进行分类。
2. 图边结构预测任务：图中节点与节点之间的边关系也存在多种类型，该任务是对节点和节点之间关系的预测。
3. 图的分类：该任务是对整个图进行分类，基本思路是将图中节点的特征聚合起来作为图的特征，再进行分类。 

## 学界发展情况

近年来，图神经网络迎来了快速爆发期。在理论研究方面，相关工作对图神经网络的原理解释、变体模型以及对各种图数据的拓展适配等进行了研究。统计近一年各大顶级会议上的相关论文，可以发现图神经网络成为最大的研究热点。

![2.jpg](./assets/2(12).jpg)

## 业界发展情况

在应用实践方面，图神经网络展现出前所未有的渗透性，从视觉推理到开放性的阅读理解问题，从药物分子的研发到5G芯片的设计，从交通流量预测到3D点云数据学习，可以看到图神经网络极其广阔的应用前景。

蚂蚁金服利用图神经网络模型，挖掘设备共用图中“正常用户”和“骗保团伙”的关系模式，从而实现了对恶意账户的识别。图中每个节点都有自己的特征信息，通过这些特征信息，可以挖掘某一用户节点所关联的设备节点信息，当某一个用户关联众多设备时，可以认为该用户存在高危风险。同时，基于图中的关联关系，与该恶意用户及关联设备相互连接的节点也可能存在高危风险。

![](./assets/image3(11).png)

滴滴出行研究了一种基于时空多图卷积神经网络的网约车需求量预测模型。通过分析区域之间复杂的时空依赖关系，对网约车需求量进行准确预测，指导车辆的调度，提高车辆的利用率，减少等待时间，并在一定程度上缓解了交通的拥堵。

![](./assets/image4(12).png)

阿里利用图神经网络，从用户行为日志、内容属性等不同维度挖掘Query（查询词）、Item（商品）和Ad（广告）的多种关系。对于在线请求场景，通过计算用户查询词向量、前置行为中节点向量和广告节点向量之间的距离进行高效的向量化最近邻检索，从而快速匹配到符合用户意图的广告并推荐给用户。

![](./assets/image5(12).png)

## 图论基本概念

针对非欧几里得结构化数据表示问题，研究者们引入了图论中抽象意义上的图（Graph）来表示非欧几里得结构化数据。

图（Graph）***G***由顶点集合以及连边集合构成，通常可以定

义为如下形式：

![](./assets/image7(9).png)

顶点集合（ Vertex ） ***V***可以表示为

![](./assets/image8(11).png)

边集合（ Edge ）***E***可以表示为

![](./assets/image9(8).png)

## 图的表示形式

常采用顶点的度矩阵、邻接矩阵以及拉普拉斯矩阵等对图进行刻画。

顶点的度矩阵（ Degree ）***D***：与该顶点相关联的边的条数

![](./assets/image10(6).png)

邻接矩阵（ Adjacency matrix ）***A***：图结构的常用表示方法

![](./assets/image11(6).png)

拉普拉斯矩阵（ Laplacian matrix ）***L***：图结构的一种表示方法

![](./assets/image12(5).png)

下图给出了连通图及对应的度矩阵、邻接矩阵 、拉普拉斯矩阵 的示例 。

![](./assets/image13(5).png)

## 图神经网络模型

### 图嵌入模型

图嵌入（ Graph Embedding ）是指，将图中的节点、边或子图由低维连续向量进行表征。为了得到图嵌入表征，可以利用图中的消息传播机制。图中的消息传播机制包括两个步骤：消息汇聚（ aggregation/combine ），节点更新（ update ）。消息汇聚是指根据周围邻居节点特征，节点更新是指学习中心节点的嵌入表示。图中的消息传播机制可以由下式进行表征。

![](./assets/image14(5).png)

式中 ， □表示可导且与输入顺序无关的函数，例如求和、均值或最大值函数等； γ 和 φ 表示可导函数，例如多层感知器 。

![3.png](./assets/3(43).png)

### 图卷积神经网络

在图卷积神经网络中，层与层之间的传播方式为：

![](./assets/image16(3).png)

式中 ，![截图.JPG](./assets/1626078224369086293.jpeg)， 其中 *I*为单位矩阵 ， *A*为邻接矩阵 ， ![截图.PNG](./assets/1626078745078097551.png)为![9.PNG](./assets/9(2).png)的度矩阵 （ degree matrix ）， *H*( *l*) 为第 *l*层的特征 ， σ 为非线性激活函数 ， *W*( *l*) 为第 *l*层的权重矩阵。

下图为图卷积神经网络的示意图，图卷积神经网络的输入为一张图，通过若干层后节点特征从 *X*变为 *Z*，共享中间多个隐层中 *A*参数。

![](./assets/image20(3).png)

图 3.3 图卷积神经网络

构造一个两层的图卷积神经网络，激活函数分别采用 ReLU 和 Softmax ，则整体的正向传播的公式为：

![](./assets/image21(3).png)

最后，根据特征 *Z*，可以做下游任务，如节点分类任务、图分类任务、节点连接预测任务等。

### 图注意力网络

注意力机制可以理解成一个加权求和的过程：对于一个给定的 query ，有一系列的 value 和与之一一对应的 key ，那么如何计算 query 的结果呢？很简单，计算 query 与所有 key 的相似度，然后根据相似度对所有的 value 加权求和。这个相似度就是 attention coefficients ，计算公式如下：

![](./assets/image22(3).png)

![](./assets/image23(3).png)

式中， *a*为前馈神经网络的权重系数， || 代表拼接操作。

![](./assets/image24(2).png)

利用注意力机制，可以对图中各节点特征进行更新：

![](./assets/image25(2).png)

利用多头注意力机制，可以用 *K*个权重系数分别对节点特征进行更新：

![](./assets/image26(2).png)

![](./assets/image27.png)

图注意力网络的优点包括：可以在不同的节点上进行并行计算、可以同时对拥有不同度的节点进行处理、可以对从未见过的图结构进行处理并用于解决归纳学习问题。

### 异质图注意力网络

GCN直接在同质图上操作，并根据其邻域的属性诱导融合得到当前节点的嵌入表示。在同质图中，每层的传播规则如下式所示

![](./assets/image28.png)

在异质网络中，节点有多种类型*T*={τ1, τ2, τ3, …}，GCN不能直接应用于异质网络。为了解决这个问题，可以采用异质图卷积，考虑各种类型信息的异质性，并利用类型相关的变换矩阵将它们投射到公共的隐式空间中。

![](./assets/image29.png)

当给定某特定节点时，不同类型的相邻节点可能对其具有不同的影响，例如，相同类型的相邻节点可能会携带更有用的信息，而相同类型的不同相邻节点也会具有不同的重要性。因此，可以设计一种异质网络的双层注意力机制。

![](./assets/image30.png)

当前图神经网络平台研发的难点在于缺少统一的算法框架，同时需要提升数据处理的效率。图数据的遍历及其与深度学习的交互会导致图的运算效率大大降低，这也是图深度学习一直无法落地的瓶颈之一。如果想要在性能上有所突破，就需要重新设计一个新的图深度学习框架，以下介绍华为云图神经网络框架。

（1）基于图引擎的GNN新框架：在ModelArts中高效神经网络训练算子的基础上，结合图引擎服务（Graph Engine Service，简称GES）既有的高性能图计算框架平台能力，利用图引擎高并发、低延时的特点，将GNN的训练过程高度并行化，如将边上的跳转概率估计、顶点邻域采样、负样本构建等，都化解为每个顶点的局部操作；系统提供了动态调度器，让这些局部操作可高度并行化执行，就能极大提升系统的总体吞吐量。

（2）多种GNN算法框架统一化：使用统一架构实现了非监督的大规模图嵌入（例如DeepWalk、Node2Vec）和半监督的图卷积（例如GCN、GraphSAGE）等多类GNN算法，降低了系统的维护成本。

（3）GNN与图数据管理一体化：企业级GNN应用通常都不会是一次性计算，而且数据规模也很大，因此这些数据必须要被维护和管理起来。而现有的GNN通常不具备这种能力，用户只能另建数据库维护，计算的时候再把数据整体导出。不仅资源消耗大，也引入数据一致性等诸多问题。而GES采用属性图数据模型(Property Graph)和生态兼容的事实标准Gremlin图查询语言进行分布式图数据管理和维护，需要训练的时候则在图引擎内本地调用各类算子，并发执行，降低了端到端的性能损耗。
